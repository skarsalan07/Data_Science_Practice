{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba4631-de5f-4166-a7fc-27d3c2a8fc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b8b6fb40-f6a7-4e9b-95d9-ceeed5ac1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skars\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train:\n",
      "   specialisation_encoded\n",
      "0                     0.0\n",
      "1                     1.0\n",
      "2                     1.0\n",
      "3                     1.0\n",
      "4                     1.0\n",
      "X_train before dropping 'specialisation':\n",
      "   10th %  12th %  Degree % Work exp specialisation  Mba %  Gender_M  \\\n",
      "0   65.00   68.00     64.00       No        Mkt&Fin  57.80       1.0   \n",
      "1   59.96   42.16     61.26       No         Mkt&HR  65.48       1.0   \n",
      "2   56.00   52.00     52.00       No         Mkt&HR  59.43       1.0   \n",
      "3   76.00   80.00     78.00      Yes         Mkt&HR  70.48       1.0   \n",
      "4   62.00   47.00     50.00       No         Mkt&HR  54.96       1.0   \n",
      "\n",
      "   12th Stream_Commerce  12th Stream_Science  Degree stream_Others  \\\n",
      "0                   0.0                  0.0                   0.0   \n",
      "1                   0.0                  1.0                   0.0   \n",
      "2                   0.0                  1.0                   0.0   \n",
      "3                   0.0                  1.0                   0.0   \n",
      "4                   1.0                  0.0                   0.0   \n",
      "\n",
      "   Degree stream_Sci&Tech  SSC Board_Others  specialisation_encoded  \n",
      "0                     0.0               0.0                     0.0  \n",
      "1                     1.0               1.0                     1.0  \n",
      "2                     1.0               0.0                     1.0  \n",
      "3                     1.0               0.0                     1.0  \n",
      "4                     0.0               0.0                     1.0  \n",
      "Final X_train:\n",
      "   10th %  12th %  Degree % Work exp  Mba %  Gender_M  12th Stream_Commerce  \\\n",
      "0   65.00   68.00     64.00       No  57.80       1.0                   0.0   \n",
      "1   59.96   42.16     61.26       No  65.48       1.0                   0.0   \n",
      "2   56.00   52.00     52.00       No  59.43       1.0                   0.0   \n",
      "3   76.00   80.00     78.00      Yes  70.48       1.0                   0.0   \n",
      "4   62.00   47.00     50.00       No  54.96       1.0                   1.0   \n",
      "\n",
      "   12th Stream_Science  Degree stream_Others  Degree stream_Sci&Tech  \\\n",
      "0                  0.0                   0.0                     0.0   \n",
      "1                  1.0                   0.0                     1.0   \n",
      "2                  1.0                   0.0                     1.0   \n",
      "3                  1.0                   0.0                     1.0   \n",
      "4                  0.0                   0.0                     0.0   \n",
      "\n",
      "   SSC Board_Others  specialisation_encoded  \n",
      "0               0.0                     0.0  \n",
      "1               1.0                     1.0  \n",
      "2               0.0                     1.0  \n",
      "3               0.0                     1.0  \n",
      "4               0.0                     1.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12603435659325257"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.read_csv(\"Placement_Data_Full_Class.csv\")\n",
    "df.drop(columns = [\"Sno\",'status'],inplace = True)\n",
    "df.isnull().mean()*100\n",
    "\n",
    "df['salary'] = df['salary'].fillna(df['salary'].mean())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 2)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False,drop = 'first',handle_unknown='ignore')\n",
    "ohe.fit(X_train[['Gender','12th Stream','Degree stream','SSC Board']])\n",
    "\n",
    "X_train_trans = ohe.transform(X_train[['Gender','12th Stream','Degree stream','SSC Board']])\n",
    "X_test_trans = ohe.transform(X_test[['Gender','12th Stream','Degree stream','SSC Board']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans,columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "X_test_trans = pd.DataFrame(X_test_trans,columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "X_train_trans.reset_index(drop=True, inplace=True)\n",
    "X_test_trans.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the transformed columns with the original DataFrames\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "\n",
    "# Drop the original columns that were encoded\n",
    "X_train.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe1 = OrdinalEncoder(categories = [['Central','Others']])\n",
    "oe2 = OrdinalEncoder(categories = [['Central','Others']])\n",
    "# X_train['HSC Board'].unique()\n",
    "oe1.fit(X_train[['HSC Board']])\n",
    "X_train_trans= oe1.transform(X_train[['HSC Board']])\n",
    "X_test_trans= oe1.transform(X_test[['HSC Board']])\n",
    "\n",
    "X_train_trans = pd.DataFrame(X_train_trans,columns=oe1.get_feature_names_out(['HSC Board']))\n",
    "X_test_trans = pd.DataFrame(X_test_trans,columns=oe1.get_feature_names_out(['HSC Board']))\n",
    "X_train_trans.reset_index(drop=True, inplace=True)\n",
    "X_test_trans.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the transformed columns with the original DataFrames\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "\n",
    "# Drop the original columns that were encoded\n",
    "X_train.drop(['HSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['HSC Board'], axis=1, inplace=True)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Define the OrdinalEncoder with appropriate categories\n",
    "oe2 = OrdinalEncoder(categories=[['Mkt&Fin', 'Mkt&HR']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit the encoder on the 'specialisation' column\n",
    "oe2.fit(X_train[['specialisation']])\n",
    "\n",
    "# Transform both the training and test data\n",
    "X_train_trans = oe2.transform(X_train[['specialisation']])\n",
    "X_test_trans = oe2.transform(X_test[['specialisation']])\n",
    "\n",
    "# Convert the transformed arrays to DataFrames with appropriate column names\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['specialisation_encoded'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['specialisation_encoded'])\n",
    "\n",
    "# Reset index to avoid mismatches when concatenating\n",
    "X_train_trans.reset_index(drop=True, inplace=True)\n",
    "X_test_trans.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the transformed data to verify it\n",
    "print(\"Transformed X_train:\")\n",
    "print(X_train_trans.head())\n",
    "\n",
    "# Concatenate the transformed columns with the original DataFrames\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "\n",
    "# Check the DataFrame before dropping the original column\n",
    "print(\"X_train before dropping 'specialisation':\")\n",
    "print(X_train.head())\n",
    "\n",
    "# Drop the original 'specialisation' column (if necessary)\n",
    "X_train.drop(['specialisation'], axis=1, inplace=True)\n",
    "X_test.drop(['specialisation'], axis=1, inplace=True)\n",
    "\n",
    "# Check the final DataFrame\n",
    "print(\"Final X_train:\")\n",
    "print(X_train.head())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train[['10th %','12th %','Degree %','Mba %']])\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_test_scaled = scaler.transform(X_test[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "\n",
    "# Convert the scaled arrays to DataFrames with appropriate column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "\n",
    "# Reset index to avoid mismatches when concatenating\n",
    "X_train_scaled.reset_index(drop=True, inplace=True)\n",
    "X_test_scaled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop the original columns from X_train and X_test\n",
    "X_train.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "X_test.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the scaled columns with the original DataFrames\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_scaled], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_scaled], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Define the OrdinalEncoder with appropriate categories\n",
    "oe2 = OrdinalEncoder(categories=[['No', 'Yes']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit the encoder on the 'specialisation' column\n",
    "oe2.fit(X_train[['Work exp']])\n",
    "\n",
    "# Transform both the training and test data\n",
    "X_train_trans = oe2.transform(X_train[['Work exp']])\n",
    "X_test_trans = oe2.transform(X_test[['Work exp']])\n",
    "\n",
    "# Convert the transformed arrays to DataFrames with appropriate column names\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['Work exp_new'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['Work exp_new'])\n",
    "\n",
    "# Reset index to avoid mismatches when concatenating\n",
    "X_train_trans.reset_index(drop=True, inplace=True)\n",
    "X_test_trans.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Concatenate the transformed columns with the original DataFrames\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "\n",
    "\n",
    "# Drop the original 'specialisation' column (if necessary)\n",
    "X_train.drop(['Work exp'], axis=1, inplace=True)\n",
    "X_test.drop(['Work exp'], axis=1, inplace=True)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86920771-ed98-4a23-bcd5-deca973956ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.12603435659325257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skars\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12th Stream_Commerce</th>\n",
       "      <th>12th Stream_Science</th>\n",
       "      <th>Degree stream_Others</th>\n",
       "      <th>Degree stream_Sci&amp;Tech</th>\n",
       "      <th>SSC Board_Others</th>\n",
       "      <th>specialisation_encoded</th>\n",
       "      <th>10th %</th>\n",
       "      <th>12th %</th>\n",
       "      <th>Degree %</th>\n",
       "      <th>Mba %</th>\n",
       "      <th>Work exp_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.198942</td>\n",
       "      <td>0.154153</td>\n",
       "      <td>-0.294235</td>\n",
       "      <td>-0.760678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.666933</td>\n",
       "      <td>-2.186095</td>\n",
       "      <td>-0.676470</td>\n",
       "      <td>0.572530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.034639</td>\n",
       "      <td>-1.294917</td>\n",
       "      <td>-1.968256</td>\n",
       "      <td>-0.477719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822465</td>\n",
       "      <td>1.240956</td>\n",
       "      <td>1.658789</td>\n",
       "      <td>1.440503</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.477508</td>\n",
       "      <td>-1.747751</td>\n",
       "      <td>-2.247260</td>\n",
       "      <td>-1.253687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843873</td>\n",
       "      <td>1.874924</td>\n",
       "      <td>0.263772</td>\n",
       "      <td>0.124655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246763</td>\n",
       "      <td>-0.497928</td>\n",
       "      <td>0.853864</td>\n",
       "      <td>1.150600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.645162</td>\n",
       "      <td>0.063586</td>\n",
       "      <td>1.658789</td>\n",
       "      <td>1.101993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.198942</td>\n",
       "      <td>0.788121</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>0.430182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.777481</td>\n",
       "      <td>-1.385484</td>\n",
       "      <td>-1.131246</td>\n",
       "      <td>-0.588819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     12th Stream_Commerce  12th Stream_Science  Degree stream_Others  \\\n",
       "0                     0.0                  0.0                   0.0   \n",
       "1                     0.0                  1.0                   0.0   \n",
       "2                     0.0                  1.0                   0.0   \n",
       "3                     0.0                  1.0                   0.0   \n",
       "4                     1.0                  0.0                   0.0   \n",
       "..                    ...                  ...                   ...   \n",
       "167                   1.0                  0.0                   0.0   \n",
       "168                   0.0                  1.0                   0.0   \n",
       "169                   0.0                  1.0                   0.0   \n",
       "170                   1.0                  0.0                   0.0   \n",
       "171                   1.0                  0.0                   0.0   \n",
       "\n",
       "     Degree stream_Sci&Tech  SSC Board_Others  specialisation_encoded  \\\n",
       "0                       0.0               0.0                     0.0   \n",
       "1                       1.0               1.0                     1.0   \n",
       "2                       1.0               0.0                     1.0   \n",
       "3                       1.0               0.0                     1.0   \n",
       "4                       0.0               0.0                     1.0   \n",
       "..                      ...               ...                     ...   \n",
       "167                     0.0               1.0                     1.0   \n",
       "168                     1.0               1.0                     1.0   \n",
       "169                     0.0               1.0                     0.0   \n",
       "170                     0.0               0.0                     0.0   \n",
       "171                     0.0               0.0                     1.0   \n",
       "\n",
       "       10th %    12th %  Degree %     Mba %  Work exp_new  \n",
       "0   -0.198942  0.154153 -0.294235 -0.760678           0.0  \n",
       "1   -0.666933 -2.186095 -0.676470  0.572530           0.0  \n",
       "2   -1.034639 -1.294917 -1.968256 -0.477719           0.0  \n",
       "3    0.822465  1.240956  1.658789  1.440503           1.0  \n",
       "4   -0.477508 -1.747751 -2.247260 -1.253687           0.0  \n",
       "..        ...       ...       ...       ...           ...  \n",
       "167  1.843873  1.874924  0.263772  0.124655           0.0  \n",
       "168  0.246763 -0.497928  0.853864  1.150600           0.0  \n",
       "169  1.645162  0.063586  1.658789  1.101993           0.0  \n",
       "170 -0.198942  0.788121  0.403274  0.430182           1.0  \n",
       "171 -1.777481 -1.385484 -1.131246 -0.588819           1.0  \n",
       "\n",
       "[172 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"Placement_Data_Full_Class.csv\")\n",
    "df.drop(columns=[\"Sno\", 'status'], inplace=True)\n",
    "df['salary'] = df['salary'].fillna(df['salary'].mean())\n",
    "\n",
    "# Split data into features and target\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# One-Hot Encoding\n",
    "ohe = OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore')\n",
    "ohe.fit(X_train[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "\n",
    "X_train_trans = ohe.transform(X_train[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "X_test_trans = ohe.transform(X_test[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "\n",
    "# Concatenate and drop original columns\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "\n",
    "# Ordinal Encoding for 'HSC Board'\n",
    "oe1 = OrdinalEncoder(categories=[['Central', 'Others']])\n",
    "oe1.fit(X_train[['HSC Board']])\n",
    "X_train_trans = oe1.transform(X_train[['HSC Board']])\n",
    "X_test_trans = oe1.transform(X_test[['HSC Board']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['HSC Board'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['HSC Board'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['HSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['HSC Board'], axis=1, inplace=True)\n",
    "\n",
    "# Ordinal Encoding for 'specialisation'\n",
    "oe2 = OrdinalEncoder(categories=[['Mkt&Fin', 'Mkt&HR']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "oe2.fit(X_train[['specialisation']])\n",
    "X_train_trans = oe2.transform(X_train[['specialisation']])\n",
    "X_test_trans = oe2.transform(X_test[['specialisation']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['specialisation_encoded'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['specialisation_encoded'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['specialisation'], axis=1, inplace=True)\n",
    "X_test.drop(['specialisation'], axis=1, inplace=True)\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_train_scaled = scaler.transform(X_train[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_test_scaled = scaler.transform(X_test[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "\n",
    "# Concatenate and drop original columns\n",
    "X_train.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "X_test.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_scaled], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_scaled], axis=1)\n",
    "\n",
    "# Ordinal Encoding for 'Work exp'\n",
    "oe3 = OrdinalEncoder(categories=[['No', 'Yes']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "oe3.fit(X_train[['Work exp']])\n",
    "X_train_trans = oe3.transform(X_train[['Work exp']])\n",
    "X_test_trans = oe3.transform(X_test[['Work exp']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['Work exp_new'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['Work exp_new'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['Work exp'], axis=1, inplace=True)\n",
    "X_test.drop(['Work exp'], axis=1, inplace=True)\n",
    "\n",
    "# Linear Regression and evaluation\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "X_train.drop(columns ='Gender_M',inplace = True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e9f50f77-3f58-4705-b58b-5ec33c67f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.12603435659325257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skars\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"Placement_Data_Full_Class.csv\")\n",
    "df.drop(columns=[\"Sno\", 'status'], inplace=True)\n",
    "df['salary'] = df['salary'].fillna(df['salary'].mean())\n",
    "\n",
    "# Split data into features and target\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# One-Hot Encoding\n",
    "ohe = OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore')\n",
    "ohe.fit(X_train[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "\n",
    "X_train_trans = ohe.transform(X_train[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "X_test_trans = ohe.transform(X_test[['Gender', '12th Stream', 'Degree stream', 'SSC Board']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=ohe.get_feature_names_out(['Gender', '12th Stream', 'Degree stream', 'SSC Board']))\n",
    "\n",
    "# Concatenate and drop original columns\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['Gender', '12th Stream', 'Degree stream', 'SSC Board'], axis=1, inplace=True)\n",
    "\n",
    "# Ordinal Encoding for 'HSC Board'\n",
    "oe1 = OrdinalEncoder(categories=[['Central', 'Others']])\n",
    "oe1.fit(X_train[['HSC Board']])\n",
    "X_train_trans = oe1.transform(X_train[['HSC Board']])\n",
    "X_test_trans = oe1.transform(X_test[['HSC Board']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['HSC Board'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['HSC Board'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['HSC Board'], axis=1, inplace=True)\n",
    "X_test.drop(['HSC Board'], axis=1, inplace=True)\n",
    "\n",
    "# Ordinal Encoding for 'specialisation'\n",
    "oe2 = OrdinalEncoder(categories=[['Mkt&Fin', 'Mkt&HR']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "oe2.fit(X_train[['specialisation']])\n",
    "X_train_trans = oe2.transform(X_train[['specialisation']])\n",
    "X_test_trans = oe2.transform(X_test[['specialisation']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['specialisation_encoded'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['specialisation_encoded'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['specialisation'], axis=1, inplace=True)\n",
    "X_test.drop(['specialisation'], axis=1, inplace=True)\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_train_scaled = scaler.transform(X_train[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_test_scaled = scaler.transform(X_test[['10th %', '12th %', 'Degree %', 'Mba %']])\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "\n",
    "# Concatenate and drop original columns\n",
    "X_train.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "X_test.drop(['10th %', '12th %', 'Degree %', 'Mba %'], axis=1, inplace=True)\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_scaled], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_scaled], axis=1)\n",
    "\n",
    "# Ordinal Encoding for 'Work exp'\n",
    "oe3 = OrdinalEncoder(categories=[['No', 'Yes']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "oe3.fit(X_train[['Work exp']])\n",
    "X_train_trans = oe3.transform(X_train[['Work exp']])\n",
    "X_test_trans = oe3.transform(X_test[['Work exp']])\n",
    "X_train_trans = pd.DataFrame(X_train_trans, columns=['Work exp_new'])\n",
    "X_test_trans = pd.DataFrame(X_test_trans, columns=['Work exp_new'])\n",
    "\n",
    "# Concatenate and drop original column\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_trans], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_trans], axis=1)\n",
    "X_train.drop(['Work exp'], axis=1, inplace=True)\n",
    "X_test.drop(['Work exp'], axis=1, inplace=True)\n",
    "\n",
    "# Linear Regression and evaluation\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and preprocessing objects\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)\n",
    "\n",
    "with open('ohe.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe, f)\n",
    "\n",
    "with open('oe1.pkl', 'wb') as f:\n",
    "    pickle.dump(oe1, f)\n",
    "\n",
    "with open('oe2.pkl', 'wb') as f:\n",
    "    pickle.dump(oe2, f)\n",
    "\n",
    "with open('oe3.pkl', 'wb') as f:\n",
    "    pickle.dump(oe3, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "882acdba-e2ce-4d77-a82d-e6273bb4bc36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:448\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 448\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     18\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     19\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearRegression())\n\u001b[0;32m     21\u001b[0m ])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Save the pipeline\u001b[39;00m\n\u001b[0;32m     27\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(pipeline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    727\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    424\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    425\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:456\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    453\u001b[0m             column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define your column transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'), ['Gender', '12th Stream', 'Degree stream', 'SSC Board']),\n",
    "        ('hsc', OrdinalEncoder(categories=[['Central', 'Others']]), ['HSC Board']),\n",
    "        ('spec', OrdinalEncoder(categories=[['Mkt&Fin', 'Mkt&HR']], handle_unknown='use_encoded_value', unknown_value=-1), ['specialisation']),\n",
    "        ('work', OrdinalEncoder(categories=[['No', 'Yes']], handle_unknown='use_encoded_value', unknown_value=-1), ['Work exp']),\n",
    "        ('num', StandardScaler(), ['10th %', '12th %', 'Degree %', 'Mba %'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(pipeline, 'pipeline.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
